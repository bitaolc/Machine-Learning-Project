---
title: "Machine Learning Project"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(caret)
library(rpart)
library(rattle)
library(randomForest)
```

###Introduction
The goal of this project is to predict the manner in which parcipants did the exercise by using data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. More information is available at: http://web.archive.org/web/20161224072740/http:/groupware.les.inf.puc-rio.br/har

###Reading and Cleaning Data
```{r read_data, include=FALSE}
training_raw <- read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"), stringsAsFactors = F)
testing_raw <- read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"), stringsAsFactors = F)

str(training_raw)
```

The training data set contains `r dim(training_raw)[1]` observations and `r dim(training_raw)[2]` variables, while the testing data set contains `r dim(testing_raw)[1]` observations and `r dim(testing_raw)[2]` variables. The "classe" variable in the training set is the outcome to predict. There are lots of variables in the training dataset that contain too many NAs/ blank, so we need to check and remove them. The first 7 columns are not related to the result, so we will also remove them from the training dataset. 

```{r clean_data, include=FALSE}
sum(training_raw[,1] != seq(1:19622)) #need remove the first column
col_remove <- which(colSums(is.na(training_raw) | training_raw=="") > 0.8*dim(training_raw)[1]) 
training <- training_raw[,-c(1:7,col_remove)]
testing <- testing_raw[,-c(1,col_remove)]
```

After cleaning, the training dataset has `r dim(training)[2]` columns. Then split the cleaned training set into a training data set (70%) and a validation data set (30%). Since the test dataset is independent to the training dataset, we would use the cross-validation techinique. It also offers higher accuracy. 

```{r}
set.seed(1000) # For reproducibile purpose
inTrain <- createDataPartition(training$classe, p=0.70, list=F)
trainData <- training[inTrain, ]
testData <- training[-inTrain, ]
```

###Machine Learning Models

*Classification Tree*

The tree plot is shown as below: 

```{r warning=FALSE, comment=NA}
set.seed(1000)
model1 <- rpart(classe ~ ., data=trainData, method="class")
#model1 <- train(classe ~ ., data=trainData, method="rpart", trControl=trainControl(method="cv", number = 5))
fancyRpartPlot(model1)
predict1 <- predict(model1, testData, type = "class")
accuracy1 <- confusionMatrix(table(predict1, testData$classe))
accuracy1
```
The accuracy of the classification tree model is `r round(accuracy1$overall[1],3)`, which is a little bit lower. We need to try another model. 

\newpage

*Random Forests*


```{r comment=NA}
set.seed(1000)
#model2 <- train(classe~., data=trainData, method="rf", trControl=trainControl(method="cv", number = 5), verbose=FALSE)
model2 <- randomForest(as.factor(classe) ~ ., data=trainData)

predict2 <- predict(model2, testData, type = "class")
accuracy2 <- confusionMatrix(table(testData$classe,predict2))
accuracy2

plot(model2,main="Accuracy of Random forest model by number of predictors")
```

The accuracy of the random forests model is `r round(accuracy2$overall[1],3)`. The expected out-of-sample error is 100-99.49 = 0.51%. We will use it to predict the values of classe for the test data set.

###Predicting Results and Conclusion

The classes of the 20 test cases are shown as following: 
```{r comment=NA}
FinalTest <- predict(model2,newdata=testing)
FinalTest
```

\newpage

###References
Ugulino, W.; Cardador, D.; Vega, K.; Velloso, E.; Milidiu, R.; Fuks, H. Wearable Computing: Accelerometers' Data Classification of Body Postures and Movements. Proceedings of 21st Brazilian Symposium on Artificial Intelligence. Advances in Artificial Intelligence - SBIA 2012. In: Lecture Notes in Computer Science. , pp. 52-61. Curitiba, PR: Springer Berlin / Heidelberg, 2012. ISBN 978-3-642-34458-9. DOI: 10.1007/978-3-642-34459-6_6.

Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.

Ugulino, W.; Ferreira, M.; Velloso, E.; Fuks, H. Virtual Caregiver: Colaboração de Parentes no Acompanhamento de Idosos. Anais do SBSC 2012, IX Simpósio Brasileiro de Sistemas Colaborativos , pp. 43-48. São Paulo, SP: IEEE, 2012. ISBN 978-0-7695-4890-6.

